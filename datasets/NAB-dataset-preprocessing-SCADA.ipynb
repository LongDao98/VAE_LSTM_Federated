{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import plot, ion, show, savefig, cla, figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to load and process original csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function load one .cvs (a sequence)\n",
    "#for scada files ONLY\n",
    "def load_data(dataset, csv_folder='./NAB-known-anomaly/csv-files/'):\n",
    "    filename = dataset + '.csv'\n",
    "    data_file = os.path.join(csv_folder, filename)\n",
    "    t_unit = 'time unit'        \n",
    "    \n",
    "    t = []\n",
    "    readings = []\n",
    "    idx_anomaly = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    with open(data_file) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        #print(\"\\n--> Anomalies occur at:\")\n",
    "        for row in readCSV:\n",
    "            if i > 0:\n",
    "                if row[-1] == '1':\n",
    "                    if j < 205972:\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                    idx_anomaly.append(i)\n",
    "                t.append(i)\n",
    "                readings.append(np.array(row[:-1]).astype(np.float))\n",
    "            j = j + 1        \n",
    "            i = i + 1\n",
    "    t = np.asarray(t)\n",
    "    readings = np.asarray(readings)\n",
    "    print(\"\\nOriginal csv file contains {} timestamps.\".format(t.shape))\n",
    "    print(\"Processed time series contain {} readings.\".format(readings.shape))\n",
    "    #print(\"Anomaly indices are {}\".format(idx_anomaly))\n",
    "    \n",
    "    return t, t_unit, readings, idx_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 16) readings.\n"
     ]
    }
   ],
   "source": [
    "t, t_unit, readings, idx_anomaly = load_data('scada2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 2. , 0. , 0.4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array((1,2,3,0,5,6,7,0.4))\n",
    "a = a[a<(2+1)]\n",
    "#np.arange(3,30)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_runs(x):\n",
    "    \"\"\"Find runs of consecutive items in an array.\"\"\"\n",
    "\n",
    "    # ensure array\n",
    "    x = np.asanyarray(x)\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError('only 1D array supported')\n",
    "    n = x.shape[0]\n",
    "\n",
    "    # handle empty array\n",
    "    if n == 0:\n",
    "        return np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    else:\n",
    "        # find run starts\n",
    "        loc_run_start = np.empty(n, dtype=bool)\n",
    "        loc_run_start[0] = True\n",
    "        np.not_equal(x[:-1], x[1:], out=loc_run_start[1:])\n",
    "        run_starts = np.nonzero(loc_run_start)[0]\n",
    "\n",
    "        # find run values\n",
    "        run_values = x[loc_run_start]\n",
    "\n",
    "        # find run lengths\n",
    "        run_lengths = np.diff(np.append(run_starts, n))\n",
    "\n",
    "        return run_values, run_starts, run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>function</th>\n",
       "      <th>length</th>\n",
       "      <th>setpoint</th>\n",
       "      <th>gain</th>\n",
       "      <th>reset rate</th>\n",
       "      <th>deadband</th>\n",
       "      <th>cycle time</th>\n",
       "      <th>rate</th>\n",
       "      <th>system mode</th>\n",
       "      <th>control scheme</th>\n",
       "      <th>pump</th>\n",
       "      <th>solenoid</th>\n",
       "      <th>pressure measurement</th>\n",
       "      <th>crc rate</th>\n",
       "      <th>command respond</th>\n",
       "      <th>binary result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.013693</td>\n",
       "      <td>-0.473801</td>\n",
       "      <td>-0.823855</td>\n",
       "      <td>-0.088897</td>\n",
       "      <td>0.232286</td>\n",
       "      <td>-1.318181</td>\n",
       "      <td>-0.003811</td>\n",
       "      <td>-0.140748</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>-0.619606</td>\n",
       "      <td>0.719006</td>\n",
       "      <td>-0.685442</td>\n",
       "      <td>-0.913608</td>\n",
       "      <td>-0.053623</td>\n",
       "      <td>-0.826166</td>\n",
       "      <td>0.997809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.013693</td>\n",
       "      <td>-0.473801</td>\n",
       "      <td>0.178277</td>\n",
       "      <td>-0.088897</td>\n",
       "      <td>0.232286</td>\n",
       "      <td>-1.318181</td>\n",
       "      <td>-0.003811</td>\n",
       "      <td>-0.140748</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>-0.619606</td>\n",
       "      <td>0.719006</td>\n",
       "      <td>-0.685442</td>\n",
       "      <td>-0.913608</td>\n",
       "      <td>-0.053623</td>\n",
       "      <td>-1.015153</td>\n",
       "      <td>-1.002193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013693</td>\n",
       "      <td>0.267787</td>\n",
       "      <td>1.648072</td>\n",
       "      <td>-0.088897</td>\n",
       "      <td>0.232286</td>\n",
       "      <td>-1.318181</td>\n",
       "      <td>-0.003811</td>\n",
       "      <td>-0.140748</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>-0.619606</td>\n",
       "      <td>0.719006</td>\n",
       "      <td>-0.685442</td>\n",
       "      <td>-0.913608</td>\n",
       "      <td>-0.053623</td>\n",
       "      <td>0.776356</td>\n",
       "      <td>0.997809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.013693</td>\n",
       "      <td>0.267787</td>\n",
       "      <td>-0.823855</td>\n",
       "      <td>-0.088897</td>\n",
       "      <td>0.232286</td>\n",
       "      <td>-1.318181</td>\n",
       "      <td>-0.003811</td>\n",
       "      <td>-0.140748</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>-0.619606</td>\n",
       "      <td>0.719006</td>\n",
       "      <td>-0.685442</td>\n",
       "      <td>-0.913608</td>\n",
       "      <td>-0.053623</td>\n",
       "      <td>0.960185</td>\n",
       "      <td>-1.002193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.013693</td>\n",
       "      <td>-0.473801</td>\n",
       "      <td>-0.823855</td>\n",
       "      <td>-0.088897</td>\n",
       "      <td>0.232286</td>\n",
       "      <td>-1.318181</td>\n",
       "      <td>-0.003811</td>\n",
       "      <td>-0.140748</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>-0.619606</td>\n",
       "      <td>0.719006</td>\n",
       "      <td>-0.685442</td>\n",
       "      <td>-0.913608</td>\n",
       "      <td>-0.053623</td>\n",
       "      <td>-0.826166</td>\n",
       "      <td>0.997809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274623</th>\n",
       "      <td>-0.013693</td>\n",
       "      <td>-0.473801</td>\n",
       "      <td>0.178277</td>\n",
       "      <td>0.059974</td>\n",
       "      <td>0.579894</td>\n",
       "      <td>0.452878</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>-0.630065</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>1.894931</td>\n",
       "      <td>0.719006</td>\n",
       "      <td>1.458907</td>\n",
       "      <td>1.094558</td>\n",
       "      <td>-0.053623</td>\n",
       "      <td>-0.921212</td>\n",
       "      <td>-1.002193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274624</th>\n",
       "      <td>-0.013693</td>\n",
       "      <td>0.267787</td>\n",
       "      <td>1.648072</td>\n",
       "      <td>-0.237768</td>\n",
       "      <td>0.579894</td>\n",
       "      <td>0.452878</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>-0.630065</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>1.894931</td>\n",
       "      <td>0.719006</td>\n",
       "      <td>1.458907</td>\n",
       "      <td>1.094558</td>\n",
       "      <td>-0.053623</td>\n",
       "      <td>-0.267309</td>\n",
       "      <td>0.997809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274625</th>\n",
       "      <td>-0.013693</td>\n",
       "      <td>0.267787</td>\n",
       "      <td>-0.823855</td>\n",
       "      <td>-0.237768</td>\n",
       "      <td>0.579894</td>\n",
       "      <td>0.452878</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>-0.630065</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>1.894931</td>\n",
       "      <td>0.719006</td>\n",
       "      <td>1.458907</td>\n",
       "      <td>1.094558</td>\n",
       "      <td>-0.053623</td>\n",
       "      <td>0.960185</td>\n",
       "      <td>-1.002193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274626</th>\n",
       "      <td>-0.013693</td>\n",
       "      <td>-0.473801</td>\n",
       "      <td>-0.823855</td>\n",
       "      <td>-0.237768</td>\n",
       "      <td>0.579894</td>\n",
       "      <td>0.452878</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>-0.630065</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>1.894931</td>\n",
       "      <td>0.719006</td>\n",
       "      <td>1.458907</td>\n",
       "      <td>1.094558</td>\n",
       "      <td>-0.053623</td>\n",
       "      <td>-0.826166</td>\n",
       "      <td>0.997809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274627</th>\n",
       "      <td>-0.013693</td>\n",
       "      <td>-0.473801</td>\n",
       "      <td>0.178277</td>\n",
       "      <td>-0.237768</td>\n",
       "      <td>0.579894</td>\n",
       "      <td>0.452878</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>-0.630065</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>1.894931</td>\n",
       "      <td>0.719006</td>\n",
       "      <td>1.458907</td>\n",
       "      <td>1.094558</td>\n",
       "      <td>-0.053623</td>\n",
       "      <td>-0.172263</td>\n",
       "      <td>-1.002193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274628 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         address  function    length  setpoint      gain  reset rate  \\\n",
       "0      -0.013693 -0.473801 -0.823855 -0.088897  0.232286   -1.318181   \n",
       "1      -0.013693 -0.473801  0.178277 -0.088897  0.232286   -1.318181   \n",
       "2      -0.013693  0.267787  1.648072 -0.088897  0.232286   -1.318181   \n",
       "3      -0.013693  0.267787 -0.823855 -0.088897  0.232286   -1.318181   \n",
       "4      -0.013693 -0.473801 -0.823855 -0.088897  0.232286   -1.318181   \n",
       "...          ...       ...       ...       ...       ...         ...   \n",
       "274623 -0.013693 -0.473801  0.178277  0.059974  0.579894    0.452878   \n",
       "274624 -0.013693  0.267787  1.648072 -0.237768  0.579894    0.452878   \n",
       "274625 -0.013693  0.267787 -0.823855 -0.237768  0.579894    0.452878   \n",
       "274626 -0.013693 -0.473801 -0.823855 -0.237768  0.579894    0.452878   \n",
       "274627 -0.013693 -0.473801  0.178277 -0.237768  0.579894    0.452878   \n",
       "\n",
       "        deadband  cycle time      rate  system mode  control scheme      pump  \\\n",
       "0      -0.003811   -0.140748 -0.139904    -0.619606        0.719006 -0.685442   \n",
       "1      -0.003811   -0.140748 -0.139904    -0.619606        0.719006 -0.685442   \n",
       "2      -0.003811   -0.140748 -0.139904    -0.619606        0.719006 -0.685442   \n",
       "3      -0.003811   -0.140748 -0.139904    -0.619606        0.719006 -0.685442   \n",
       "4      -0.003811   -0.140748 -0.139904    -0.619606        0.719006 -0.685442   \n",
       "...          ...         ...       ...          ...             ...       ...   \n",
       "274623 -0.003673   -0.630065 -0.139904     1.894931        0.719006  1.458907   \n",
       "274624 -0.003673   -0.630065 -0.139904     1.894931        0.719006  1.458907   \n",
       "274625 -0.003673   -0.630065 -0.139904     1.894931        0.719006  1.458907   \n",
       "274626 -0.003673   -0.630065 -0.139904     1.894931        0.719006  1.458907   \n",
       "274627 -0.003673   -0.630065 -0.139904     1.894931        0.719006  1.458907   \n",
       "\n",
       "        solenoid  pressure measurement  crc rate  command respond  \\\n",
       "0      -0.913608             -0.053623 -0.826166         0.997809   \n",
       "1      -0.913608             -0.053623 -1.015153        -1.002193   \n",
       "2      -0.913608             -0.053623  0.776356         0.997809   \n",
       "3      -0.913608             -0.053623  0.960185        -1.002193   \n",
       "4      -0.913608             -0.053623 -0.826166         0.997809   \n",
       "...          ...                   ...       ...              ...   \n",
       "274623  1.094558             -0.053623 -0.921212        -1.002193   \n",
       "274624  1.094558             -0.053623 -0.267309         0.997809   \n",
       "274625  1.094558             -0.053623  0.960185        -1.002193   \n",
       "274626  1.094558             -0.053623 -0.826166         0.997809   \n",
       "274627  1.094558             -0.053623 -0.172263        -1.002193   \n",
       "\n",
       "        binary result  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "274623              1  \n",
       "274624              1  \n",
       "274625              1  \n",
       "274626              0  \n",
       "274627              0  \n",
       "\n",
       "[274628 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./NAB-known-anomaly/csv-files/scada1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18970\n",
      "162195 163611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00950141, 0.06644603, 0.37317608, 0.13186913, 0.05908807,\n",
       "       0.07057748, 0.00417454, 0.06935928, 0.06757354, 0.39569464,\n",
       "       0.47477088, 0.46336916, 0.49821839, 0.03527813, 0.03669692,\n",
       "       0.49885847])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_vals, run_starts, run_lengths = find_runs(df['binary result'])\n",
    "run_lengths = run_lengths[run_vals==0]\n",
    "run_starts = run_starts[run_vals==0]\n",
    "arg = np.argmax(run_lengths)\n",
    "print(arg)\n",
    "train_start = run_starts[arg]\n",
    "train_end = train_start + run_lengths[arg]\n",
    "print(train_start,train_end)\n",
    "#print(df['binary result'][train_start:train_end])\n",
    "#readings[train_start:train_end]\n",
    "np.std(np.array(readings), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00342136 0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.00342136,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.min(readings, axis=0)\n",
    "print(x)\n",
    "x[x==0] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots a dataset with the train/test split and known anomalies\n",
    "# Relies on helper function load_data()\n",
    "\n",
    "def process_and_save_specified_dataset(dataset, idx_split, pi_num, y_scale=5, save_file=False):\n",
    "    t, t_unit, readings, idx_anomaly = load_data(dataset)\n",
    "    \n",
    "    # split into training and test sets\n",
    "    #[0,40217]\n",
    "#[40217, 80434]\n",
    "#[80434, 120651]\n",
    "#[120651,160869]\n",
    "    split_fl = [[0,40217],[40217, 80434],[80434, 120651],[120651,160869]]\n",
    "    training = readings[split_fl[pi_num-1][0]:split_fl[pi_num-1][1]]\n",
    "    t_train = t[split_fl[pi_num-1][0]:split_fl[pi_num-1][1]]\n",
    "    \n",
    "    # normalise by training mean and std \n",
    "    train_m = np.mean(training, axis=0)\n",
    "    train_std = np.std(training, axis=0)\n",
    "    #train_std[train_std==0] = 0.2 #avoid divide by zero\n",
    "    #print(\"\\nTraining set mean is {}\".format(train_m))\n",
    "    #print(\"Training set std is {}\".format(train_std))\n",
    "    #readings_normalised = (readings - train_m) / train_std\n",
    "    #training = readings_normalised[split_fl[pi_num-1][0]:split_fl[pi_num-1][1]]\n",
    "    \n",
    "    #training = readings_normalised[idx_split[0]:idx_split[1]] \n",
    "    #160869\n",
    "    \n",
    "    if idx_split[0] == 0:\n",
    "        test = readings[idx_split[1]:]\n",
    "        t_test = t[idx_split[1]:] - idx_split[1]\n",
    "        idx_anomaly_test = np.asarray(idx_anomaly) - idx_split[1]\n",
    "    else:\n",
    "        test = [training[:idx_split[0]], training[idx_split[1]:]]\n",
    "        t_test = [t[:idx_split[0]], t[idx_split[1]:] - idx_split[1]]\n",
    "        idx_anomaly_split = np.squeeze(np.argwhere(np.asarray(idx_anomaly)>idx_split[0]))\n",
    "        idx_anomaly_test = [np.asarray(idx_anomaly[:idx_anomaly_split[0]]), \n",
    "                            np.asarray(idx_anomaly[idx_anomaly_split[0]:]) - idx_split[1]]\n",
    "    print(\"Anomaly indices in the test set are {}\".format(idx_anomaly_test))\n",
    "    \n",
    "    #if dataset = scada\n",
    "    #idx_test = [0,3000]\n",
    "    #t_test = np.arange(idx_test[1] - idx_test[0]) + 1\n",
    "    #test = readings_normalised[idx_test[0]:idx_test[1]]\n",
    "    #idx_anomaly_test = np.asarray(idx_anomaly) - idx_test[0] #+ idx_test[0]    \n",
    "    #idx_anomaly_test = idx_anomaly_test[idx_anomaly_test < (idx_test[1] + 1)]\n",
    "    #print(\"Anomaly indices in the test set are {}\".format(idx_anomaly_test))\n",
    "    \n",
    "    if save_file:\n",
    "        save_dir = './NAB-known-anomaly/'\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        np.savez(save_dir+dataset+'_'+ str(pi_num)+'.npz', t=t, t_unit=t_unit, idx_anomaly=idx_anomaly,\n",
    "                    idx_split=idx_split, training=training, test=test, train_m=train_m, train_std=train_std,\n",
    "                    t_train=t_train, t_test=t_test, idx_anomaly_test=idx_anomaly_test) #deleted readings = readings\n",
    "        print(\"\\nProcessed time series are saved at {}\".format(save_dir+dataset+'.npz'))\n",
    "    else:\n",
    "        print(\"\\nProcessed time series are not saved.\")\n",
    "        \n",
    "    print(\"t_train:\",t_train,\"t_test:\",t_test)\n",
    "\n",
    "    # plot the whole normalised sequence\n",
    "    #fig, axs = plt.subplots(1, 1, figsize=(18, 4), edgecolor='k')\n",
    "    #fig.subplots_adjust(hspace=.4, wspace=.4)\n",
    "    # axs = axs.ravel()\n",
    "    # for i in range(4):\n",
    "    #axs.plot(t, training)\n",
    "    #axs.plot(t_test,test)\n",
    "    #if idx_split[0] == 0:\n",
    "    #    axs.plot(idx_split[1]*np.ones(20), np.linspace(-y_scale,y_scale,20), 'b--')\n",
    "    #else:\n",
    "    #    for i in range(2):\n",
    "    #        axs.plot(idx_split[i]*np.ones(20), np.linspace(-y_scale,y_scale,20), 'b--')\n",
    "    #for j in range(len(idx_anomaly)):\n",
    "    #    axs.plot(idx_anomaly[j]*np.ones(20), np.linspace(-y_scale,y_scale,20), 'r--')\n",
    "    #     axs.plot(data[:,1])\n",
    "    #axs.grid(True)\n",
    "    #axs.set_xlim(0, len(t))\n",
    "    #axs.set_ylim(-y_scale, y_scale)\n",
    "    #axs.set_xlabel(\"timestamp (every {})\".format(t_unit))\n",
    "    #axs.set_ylabel(\"normalised readings\")\n",
    "    #axs.set_title(\"{} dataset\\n(normalised by train mean {:.2f} and std {:.2f})\".format(dataset, np.mean(train_m), np.mean(train_std)))\n",
    "    #axs.legend(('data', 'train test set split', 'anomalies'))\n",
    "    \n",
    "    return t, training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on ambient temperature series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 16) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada1.npz\n",
      "t_train: [    1     2     3 ... 40215 40216 40217] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 16) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada1.npz\n",
      "t_train: [40218 40219 40220 ... 80432 80433 80434] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 16) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada1.npz\n",
      "t_train: [ 80435  80436  80437 ... 120649 120650 120651] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 16) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada1.npz\n",
      "t_train: [120652 120653 120654 ... 160867 160868 160869] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 16) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada2.npz\n",
      "t_train: [    1     2     3 ... 40215 40216 40217] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 16) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada2.npz\n",
      "t_train: [40218 40219 40220 ... 80432 80433 80434] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 16) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada2.npz\n",
      "t_train: [ 80435  80436  80437 ... 120649 120650 120651] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 16) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada2.npz\n",
      "t_train: [120652 120653 120654 ... 160867 160868 160869] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 27) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada3.npz\n",
      "t_train: [    1     2     3 ... 40215 40216 40217] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 27) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada3.npz\n",
      "t_train: [40218 40219 40220 ... 80432 80433 80434] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 27) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada3.npz\n",
      "t_train: [ 80435  80436  80437 ... 120649 120650 120651] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 27) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada3.npz\n",
      "t_train: [120652 120653 120654 ... 160867 160868 160869] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 27) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada4.npz\n",
      "t_train: [    1     2     3 ... 40215 40216 40217] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 27) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada4.npz\n",
      "t_train: [40218 40219 40220 ... 80432 80433 80434] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 27) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada4.npz\n",
      "t_train: [ 80435  80436  80437 ... 120649 120650 120651] t_test: [    1     2     3 ... 68656 68657 68658]\n",
      "\n",
      "Original csv file contains (229527,) timestamps.\n",
      "Processed time series contain (229527, 27) readings.\n",
      "Anomaly indices in the test set are [    3     7    11 ... 68654 68655 68656]\n",
      "\n",
      "Processed time series are saved at ./NAB-known-anomaly/scada4.npz\n",
      "t_train: [120652 120653 120654 ... 160867 160868 160869] t_test: [    1     2     3 ... 68656 68657 68658]\n"
     ]
    }
   ],
   "source": [
    "dataset = ['scada1','scada2','scada3','scada4']\n",
    "idx_split = [0,160869]\n",
    "#40217.25\n",
    "#[0,40217]\n",
    "#[40217, 80434]\n",
    "#[80434, 120651]\n",
    "#[120651,160869]\n",
    "for name in dataset:\n",
    "    t, training = process_and_save_specified_dataset(name, idx_split, 1, save_file=True)\n",
    "    t, training = process_and_save_specified_dataset(name, idx_split, 2, save_file=True)\n",
    "    t, training = process_and_save_specified_dataset(name, idx_split, 3, save_file=True)\n",
    "    t, training = process_and_save_specified_dataset(name, idx_split, 4, save_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
